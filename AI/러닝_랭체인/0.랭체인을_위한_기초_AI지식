- LLM(Large language model): 텍스트를 입력 받아 인간과 유사한 텍스트 출력을 예측하고 생성하는 훈련된 **알고리즘**
    - 대체로 학습 데이터에서 영어가 많은 지분을 차지하기에 많은 LLM이 영어를 더 잘 다룬다.
    - 방대한 텍스트로 학습한 크고 범용적인 언어모델
    - **토큰**이라는 텍스트의 원자 단위로 확률을 추정함.
    - LLM의 예측력을 좌우하는 핵심은 **트랜스포머 신경망 아키텍처**다.
        - 가장 가능성이 높은 다음 단어들을 예측함. 문장 내 단어와 다른 모든 단어의 관계를 고려해 문맥을 파악함.
- LLM에 제공하는 지침과 입력 테스트를 **프롬프트**라고 한다.


### 지시 튜닝

- LLM을 쉽게 사용할 수 있도록 추가 훈련(**파인 튜닝**)을 실시한다.
    - 특화 데이터셋: 수작업으로 구성한 질문/답변 쌍 데이터셋, 바람직한 응답 예시를 제공. 수작업으로 만들어져서 그 수가 적다.
    - 인간 피드백을 통한 강화학습(RLHF): 출력에 대한 사용자 피드백이 앞서 사용한 수작업 데이터셋에 더해지는 형태

### 대화 튜닝

- 지시튜닝을 거친 LLM에 추가적인 튜닝을 진행해 대화에 적합하게 구성한다.
    - 업체마다 다름

- 대화 데이터셋: 여러 개의 프롬프트 - 응답 쌍으로 구성한 상호작용 형태의 파인 튜닝 데이터셋을 수작업으로 구성
- 채팅 형식: 모델의 입력, 출력 형식에 자유 형식 텍스트 위에 계층 구조를 부여. 

### 파인 튜닝

- 기본 LLM에 특정 작업 수행에 특화된 데이터셋을 추가 학습시킨 것. 
    - 지시 튜닝과 대화 튜닝을 거친 LLM은 파인튜닝을 거친 LLM이다 라고 말할 수 있다.

## 프롬프트

LLM관련 소프트엔지니어의 주된 임무는 LLM을 학습하거나 파인 튜닝을 하는게 아닌, 이미 존재하는 LLM을 활용해 애플리케이션에 기능을 구현하는데에 초점을 맞춰야한다.

### 제로샷 프롬프트

아주 단순하게 LLM에 원하는 작업을 지시하는 방법

> 미국 제 30대 대통령의 아내는 어머니가 돌아가셨을 때 몇 살이었을까?

<details>

<summary> 결과 </summary>

미국 제30대 대통령은 **캘빈 쿨리지 (Calvin Coolidge)**입니다.

그의 아내는 **그레이스 쿨리지 (Grace Coolidge)**이며, 본명은 Grace Anna Goodhue입니다.

✔️ 질문:
그레이스 쿨리지가 어머니가 돌아가셨을 때 몇 살이었는가?

📘 정보 조사:
그레이스 쿨리지 생년월일:
1879년 1월 3일

그레이스 쿨리지의 어머니 (Lemira Goodhue) 사망일:
1929년 3월 2일

🧮 나이 계산:
1929년 3월 2일 - 1879년 1월 3일 →
50세 (만 50세 생일 지남)

✅ 정답:
그레이스 쿨리지는 어머니가 돌아가셨을 때 50세였습니다.

</details>

### 사고의 연쇄(CoT)

LLM이 시간을 들여 **사고하도록** 추가 지시하는 것. LLM이 답에 도달하는 과정을 설명하도록 지시문에 삽입

> 단계별로 생각하자. 미국 제30대 대통령은 아내의 어머니가 돌아가셨을 때 몇 살이었을까?

</details>

<summary> 결과 </summary>

좋습니다. 단계별로 차근차근 생각해보죠.

✅ 1단계: 미국 제30대 대통령이 누구인지 확인
제30대 미국 대통령은 **캘빈 쿨리지 (Calvin Coolidge)**입니다.

생년월일: 1872년 7월 4일

✅ 2단계: 그의 아내가 누구인지 확인
아내: 그레이스 쿨리지 (Grace Coolidge, 결혼 전 이름 Grace Anna Goodhue)

생년월일: 1879년 1월 3일

✅ 3단계: 그레이스 쿨리지의 어머니가 언제 돌아가셨는지 확인
어머니: Lemira Goodhue

사망일: 1929년 3월 2일

✅ 4단계: 캘빈 쿨리지가 1929년 3월 2일에 몇 살이었는지 계산
캘빈 쿨리지 생년월일: 1872년 7월 4일

1929년 3월 2일 당시 나이:

1929년 7월 4일이면 57세가 됨

3월 2일은 생일 전이므로 → 아직 56세

🎯 최종 정답:
캘빈 쿨리지는 아내의 어머니가 돌아가셨을 때 56세였습니다.

</details>

'단계별로 생각하자'라고 했는데 많은 차이가 생겼다. 물론 책에서 쓰인 예제랑 모델차이가 좀 있기에 성능이 좋아져서 큰 차이가 없어 보일 수 있는데, 
예제에서 전자의 경우 답변은 1줄로 끝났으며 후자의 경우 답변이 5줄 이상으로 좀 더 상세한 느낌으로 적혀있었다. 다만 답변에 대한 정답은 다 틀렸다.

### 검색 증강 생성(RAG)

관련 있는 텍스트 조각을 찾아내, 해당 텍스트 조각을 **컨택스트**라 칭하며 프롬프트에 포함한다.

> 컨택스트: 캘빈 쿨리지 ~ 미국의 변호사 겸 정치인 이었습니다. ~ (인물 사전에 적힌 내용) 미국 제30대 대통령은 아내의 어머니가 돌아가셨을 때 몇 살이었을까?

이러한 결과 정답에 가까운 결과를 받을 수 있는데, LLM이 수학에 능하지 않아서 나이 계산값이 틀리게 나올 것이다.

### 툴 후출

프롬프트에 미리 LLM이 사용할 수 있는 외부 함수(툴) 목록과 각 함수의 용도, 출력에서 함수를 사용하고자 할 때 답변을 출력하는 방법을 포함한다.

> 툴: - calculator: 이 툴은 수학 식을 받아들이고 그 결과를 반환합니다. / - search: 이 툴은 검색 엔진 쿼리를 받아 첫 번째 검색결과를 반환합니다.

이렇게 하면 출력 형식 지침은 따르지만 이것 또한 마찬가지로 원하는 결과를 도출하지 않는다.

즉, **프롬프트 작성 기법은 서로가 결합할 때 가장 효과적이다.**


### 퓨샷 프롬프트에

LLM에 질문과 정답의 예제를 몇 가지 제공하여, 추가적인 훈련이나 파인튜닝을 거치지 않고도 새로운 작업을 수행하는 방법.

호출하는 시점에 즉석에서 적용할 수 있지만 결과가 효과적이지 못할 때도 있다. 파인튜닝을 통해서 개선이 가능하다. 때문에 파인튜닝을 하기 전에 보통은 퓨샤 프롬프트를 시도하길 권한다고한다.

## 랭체인?

- 랭체인은 LLM과 프롬프트 구성 요소와 툴을 제공하는 **오픈소스 라이브러리**. 모든 요소를 신뢰성 있게 결합해 더 큰 애플리케이션을 만들 수 있도록 지원.
- 랭체인은 위에서 설명한 각 프롬프트 작성 기법을 간단한 **추상화**로 제공해 프롬프트를 쉽게 결합할 수 있다.
- 랭체인은 툴 호출 기법에서 사용하기 편한 표준 인터페이스도 제공한다.
- RAG를 구현할 수 있도록 주요 **임베딩 모델**, **벡터 저장소**, **벡터 인덱스**와의 통합을 제공한다.(2,3장에서 다뤄짐)
- 랭그래프 라이브러리로 사고의 연쇄(CoT)를 통한 추론과 툴 호출을 결합해 **에이전트** 추상화를 제공한다.(5~8장)

챗봇에서는 이전 상호작용을 기록하고 이를 미래 상호작용에 대한 응답을 생성하는 데 참고하도록 구현하는 편이 좋은데, 이 기능을 **메모리**라고 한다.


