- LLM 모델의 지식한계
  - 비공개 데이터에 대한 질문을 한다면?
  - 지식 컷오프가 생김
    - 학습에 대한 비용이 상당히 소모되어 현재 날짜 기준의 지식도 보유하고 있지 않을 수 있는데, 이 기준날짜를 말함.
  - 위의 경우에 의해 환각(잘못된 정보를 출력하는 현상)을 일으킴
  - 
  
## 적절한 컨텍스트 선정

LLM 활용에 필요한 비공개/최신 데이터가 한두 페이지 분량의 텍스트라면 괜찮지만 양이 방대할 경우 어떻게 할 것인가

- 인덱싱: 애플리케이션이 질문에 가장 적합한 자료를 손쉽게 탐색할 수 있도록 문서를 전처리함
- 검색: LLM이 데이터를 바탕으로 정확한 답변을 생성하도록 인덱스에서 외부 데이터를 가져와 컨텍스트로 전달

2장에서는 **인덱싱**에 초점을 맞추며, 문서를 거대 언어 모델이 이해하고 검색할 수 있는 형식으로 사전 처리하는 과정을 **검색 증강 생성(RAG)**라고 한다.

문서를 전처리하고 변환하는 과정을 **인제스천(Ingestion)**이라고 하는데, 컴퓨터가 이해하고 분석하기 좋은 숫자 데이터로 전환한 뒤, 효율적인 검색 증강 생성을 위해 특화된 데이터베이스에 저장한다. 여기서 숫자 데이터는 **임베딩**이라 부르고, 특수한 유형의 데이터베이스를 **벡터 저장소**라고 부름.

## 임베딩: 텍스트를 숫자로 변환

