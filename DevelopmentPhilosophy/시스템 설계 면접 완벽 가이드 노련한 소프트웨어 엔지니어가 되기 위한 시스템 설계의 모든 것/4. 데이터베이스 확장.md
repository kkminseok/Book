데이터베이스 확장의 개념, 트레이드 오프 이러한 개념을 구현에 활용하는 일반적인 데이터베이스 설명.

데이터베이스는 상태 저장 서비스이다. 상태 저장 서비스는 일관성을 보장하기 위한 메커니즘이 있으며, 데이터 손실을 피하려면 복제가 필요하다.

강한 일관성을 위해 여러 부분을 트레이드오프 할 수 있다. 이는 가능한 한 모든 서비스를 상태를 저장하지 않고 데이터베이스 같은 상태 저장 서비스에만 상태를 유지하려는 이유다.

또, 개별 소트스에 상태를 유지하려면 동일한 사용자를 동일한 호스트로 일관되게 라우팅하는 고정 세션을 구현하기 떄문에 보통 서비스는 상태를 가지지 않는다.

상태 저장을 하는 서비스의 스토리지는 다음과 같이 분류할 수 있다.

- 데이터베이스
    - SQL
    - NoSQL
    - 키-값
- 문서
- 그래프
- 파일 스토리지
- 블록 스토리지
- 객체 스토리지

위를 기준을 토대로 어떤 데이터 베이스를 사용할지, 혹은 다른 요구사항에 따라 데이터베이스 사용 결정을 논의할 수 있다.

-----

데이터베이스를 확장하는 방법에는 복제, 분할, 샤딩 등이 있다. 복제는 복제본이라고 하는 데이터 사본을 만들어서 다른 노드에 복사하고 관리하는 것을 말한다.
분할 및 샤딩은 데이터 집합을 부분 집합으로 나눠서 여러 노드에 분산시켜 저장하고 관리한다. 때문에 단일 호스트로는 한계가 있다.

- 보통 읽기 연산을 확장하려면 데이터의 복제본의 수르 늘리면 되는데, 쓰기 확장은 그러기 쉽지 않다.

- 데이터는 샤딩될 수 있으며, 트레이드 오프는 샤드의 위치를 추적해야하는 복잡성 증대가 있지만 이점은 다음과 같다.
    - 스토리지 확장: 노드 간 샤딩을 통해 데이터베이스/테이블을 논리적 단위로 유지 가능
    - 메모리 확장: 만약 데이터베이스가 메모리에 저장되는 구조라면 확장시 노드를 늘려서 수직적 확장보다 금전적 금액을 아낄 수 있게 한다.
    - 처리 확장: 노드가 여러개 존재하므로 병렬 처리의 이점이 있다.
    - 지역성: 특정 클러스터 노드가 필요로 하는 데이터가 다른 노드의 다른 샤드가 아닌 로컬에 저장될 가능성이 높게끔 샤딩될 수 있다.

- **단일 리더 복제**기법은 쓰기 작업을 담당하는 리더가 존재하고 이 리더가 장애가 났을 경우 대처할 수 있게끔하는 보조 리더가 존재하는 아키텍처?를 의미한다.
    - ACID 일관성을 잃는 대신에 높은 트래픽의 서비스를 제공하기 위해 데이터베이스 수평확장시에 고려할 수 있다. 
    - 쓰기와 같은 작업은 주 리더 노드에서 발생하고 보조리더를 포함한 여러 팔로워들에게 데이터가 저장된다. 
        - 일관성을 잃는 이유는 팔로워들에게 데이터를 복제하면서 잃는 것을 의미한다.
    - 주 리더가 쓰기 작업 등을 실패하면 보조 리더를 주 리더로 승격시킨다. 기존 주 리더가 복구되면 보조 리더로 변경된다.

- **다중 리더 복제**기법은 쓰기 작업과 데이터베이스 저장 용량을 확장하기 위한 기술이다. 여러 노드가 리더로 지정되었기에 경쟁 조건을 처리해야 한다.
    - 각 노드의 일관성을 유지하기가 굉장히 골치 아프다.
        - 여러 노드에서 DELETE와 INSERT가 거의 비슷한 시간대에 날라온다면? 어떻게 처리 해야하는가? 순서는? 읽기 수준은? 고려해야할 부분이 많다.
    - 한 가지 방법은 INSERT/UPDATE보다 DELETE에 우선순위를 두고 INSERT/UPDATE는 무작위로 동점을 메겨 처리한다.

- **리더 없는 복제**기법은 읽기 쓰기가 어디서든 일어날 수 있는 기법이다. 경쟁 조건을 처리하는 방식은 많지만 책에서는 정족수 개념을 도입하면 된다고 한다.

- **HDFS복제**는 파일을 일정 크기(Block, 기본 128MB)로 나눠서 여러 DataNode에 분산 저장하고 이를 노드에 복제시켜 저장하는 기법이다.

-----

- 샤딩을 하면 `JOIN` 쿼리가 느려진다. 각 노드와 다른 모든 노드사이에 네트워크 트래픽을 수반한다. 
- 데이터 샘플링 통해 부하를 줄일 수 있다. 데이터 샘플링이란 데이터가 1억건이 있으면 1천만건만 뽑아서 보여주는 등의 개념이다.
- 집계를 할 때에는 단일 계층 집계와 다중 계층 집계를 통해 데이터베이스의 연산 부하를 줄일 수 있다.
    - 단일 계층 집계는 로드밸런서가 여러 호스트를 찌르고 해당 호스트들이 각 메모리에서 집계를 하여 데이터베이스에 저장하느 방식이다.
    - 다중 계층 집계는 단일 계층의 Depth을 여러개 둬서 호스트에서 집계하고 다른 호스트에서 이를 받아서 또 집계하고..하면서 데이터베이스에 저장하는 방식이다.
- 분할 기법을 사용하려면 L7 로드밸런서가 있어야한다. 로드밸런서는 특정 필터값에 따라 호스트에 요청을 전달시켜서 처리시킨다. 트래픽 불균등이 존재할 수 있다.
- 만약 호스트가 다운되면 기존에 메모리에 들고 있던 집계 데이터가 다 날라갈 것이다. 이러한 것을 방지하기 위해서는 레디스와 같은 인메모리 공유 데이터베이스에 요청을 보내 값을 저장시켜 호스트는 상태를 가지지 않게끔 수정할 수 있다.

-----

### 배치와 스트리밍 ETL

배치를 구현하는 방식
- Crontab
    - 단점: 확장성이 없음. 모든 배치가 단일 호스트에서 실행됨. SPOF문제 가능성
    - 멱등성을 제공하지 않는다. 
    - 작업Id를 둔다하면 일관성 보장 어려움
    - GUI 부재
    - 로깅이나 모니터링, 경보를 구현하지 않음.
- 에어플로
- 루이지

### 실시간 스트리밍 시스템에서의 Kafka vs RabbitMQ

- 카프카는 RabbitMQ보다 더 많은 기능을 제공하고 있기에 항상 RabbitMQ을 대체할 수 있지만 그 반대는 아니다
- RabbitMQ는 확장성이 없기에 내구성도 없다. 다운타임이 발생하면 메시지가 손실 된다. 
- 카프카는 이벤트가 소비되어도 제거되지 않아서 반복해서 소비할 수 있다. 이벤트 처리를 완료하기 전에 실패한 경우 재처리를 위함이다. 
- 카프카에서 보존 기간을 구성할 수 있다. 이를 활용하면 데이터베이스로도 사용이 가능하다. 

-> 이는 현대에서 정확하지는 않은 듯함..

-----

- 람다 아키텍처: 대용량의 데이터를 배치 + 실시간 두 경로로 처리하는 방식
구조
	1.	Batch Layer (배치 레이어)
	    •	모든 원본 데이터를 HDFS, S3 같은 저장소에 append-only로 저장
	    •	주기적으로 배치 작업(Spark, Hadoop MapReduce 등)을 돌려 전체 뷰(Serving Layer로 전달)를 계산
	    •	정확하지만 지연(latency) 발생
	2.	Speed Layer (속도 레이어)
	    •	실시간 스트리밍 시스템(Kafka + Storm/Flink/Spark Streaming 등)을 사용해 최신 데이터를 빠르게 처리
	    •	실시간 응답을 가능하게 하지만, 데이터 정확성은 떨어질 수 있음
	3.	Serving Layer
	    •	Batch Layer와 Speed Layer의 결과를 합쳐 사용자에게 제공
	    •	Batch → 정확성, Speed → 실시간성 보완

장점
	•	정확성과 실시간성을 동시에 확보 가능
	•	장애 복구가 쉬움 (원본 데이터를 다 저장하니까 재처리 가능)

단점
	•	복잡성 → 동일한 로직을 Batch/Speed Layer에 두 번 구현해야 함 (개발·운영 부담 큼)
	•	유지보수 어려움

- 카파 아키텍처:  람다 아키텍처의 단점을 줄이기 위해 등장.

구조
	•	Batch Layer 제거
	•	오직 **스트리밍 처리 엔진(예: Kafka Streams, Flink, Spark Structured Streaming)**만 사용
	•	배치 처리도 “스트리밍 데이터 재생(replay)“으로 해결
→ 즉, 데이터가 Kafka 같은 로그 저장소에 저장되어 있으면,
“처음부터 다시 읽어서 재처리”하면 배치 효과를 낼 수 있음

장점
	•	단순한 구조 (하나의 코드 경로만 유지하면 됨)
	•	실시간성과 정확성을 동시에 다룸
	•	운영 관리 부담이 적음

단점
	•	모든 상황에서 스트리밍 처리만으로 충분하지 않을 수 있음 (예: 대규모 복잡 배치 연산)
	•	배치보다 스트리밍 처리의 비용/성능이 떨어질 수 있음

-----

### 정규화와 비정규화

정규화의 특징은 다음과 같다.

- 일관성이 있고 중복 데이터가 없어 불일치 데이터가 있는 테이블이 없다.
- 하나의 테이블만 쿼리하면 되므로 삽입과 업데이트가 빠르다. 
- 중복 데이터가 없어 데이터베이스 크기가 작다. 
- 보통 열이 적은 경향이 있어서 인덱스도 적다.
- 필요한 테이블만 JOIN연산을 할 수 있다.

하지만 정규화의 단점도 존재하고 다음과 같다.

- JOIN쿼리는 결국 개별 테이블 쿼리보다 느리다.
- 사실 대부분의 쿼리에 JOIN연산이 포함된다.

때문에 JOIN 쿼리를 피하기 위해 스키마를 비정규화해 저장 공간을 속도와 맞바꾸는 경우도 있다.

-----

### 캐싱

당연하지만 캐싱의 이점은 다음과 같다.

- 성능이 빠르다.
- 구조에 따라 가용성을 증대시킬 수 있다. 데이터베이스를 사용할 수 없더라도 서비스가 굴러가게끔 할 수 있다. 하지만 캐시 설계의 목적은 고가용성은 아니다.
- 확장성도 존재한다.

캐싱에는 여러 읽기 전략이 존재한다.

- 캐시 어사이드(지연로드)
    - 캐시 먼저 조회해서 캐시 히트시 데이터를 반환하고 캐시 미스 시 데이터베이스에서 읽고 캐시에 쓰는 기법 따라서 데이터는 처음 읽을 때만 로드되며, 이를 지연 로드(Lazy load)라고함.
    - 데이터베이스에 직접 쓰기를 할 경우 캐시와 일관성이 무너질 수 있다. 때문에 TTL을 설정하거나 쓰기 통과를 사용하는 방법이 있다.
    - 캐시 미스시에는 결국 데이터베이스에서 직접 읽는 것 보다 느리다.
- 읽기 통과(read-through)
    - 애플리케이션이 직접 데이터베이스에 붙어있지 않고 캐시가 데이터베이스에 붙어서 요청을 무조건 캐시가 먼저 받는 아키텍처 구성이다.
    - 캐시 미스시에 캐시는 데이터베이스에 요청하고 데이터를 캐시한다. 그리고 데이터를 애플리케이션에 반환한다.

쓰기 전략에는 다음과 같은 전략들이 존재한다.

- 쓰기 통과 방식
    - 모든 쓰기 작업은 캐시를 거쳐 데이터베이스로 전달된다.
    - **장점**
        - 일관성이 있다. 모든 데이터베이스 쓰기 작업에 캐시 데이터가 갱신된다.
    - **단점** 
        - 쓰기 작업이 두 군데서 일어나서 느리다.
        - 새로운 캐시 노드에는 누락된 데이터와 캐시 미스가 발생하는 **콜드 스타트**문제가 있다. 캐시 어사이드로 해결 가능하다.
        - 대부분 데이터는 읽히지 않으므로 불필요한 비용 문제가 존재한다. TTL을 설정하여 어느정도 해소할 수 있다.
        - 캐시 크기가 데이터베이스보다 작다면 적절한 캐시 제거 정책이 필요하다.
- 지연 쓰기/후속 쓰기(Write-bebind)방식
    - 애플리케이션은 데이터를 캐시에 쓰지만 즉시 데이터베이스에 쓰지 않는다. 캐시는 주기적으로 갱신된 데이터베이스에 플러시한다.
    - **장점**
        - 쓰기 통과 방식보다는 빠르다. 
    - **단점**
        - 대부분의 쓰기 통과방식의 단점과 동일하다.
        - 복잡도 증대, 캐시의 높은 가용성과 성능을 보장시켜야하므로 설계가 복잡해진다.
- 쓰기 우회 방식
    - 애플리케이션은 데이터베이스에만 기록.

CSS와 같은 파일은 다운로드하고 처리한 후에야 렌더링을 시작하므로 캐싱하면 브라우저 앱 성능을 상당히 개선할 수 있다.

캐시 무효화 방식에는 밑과 같은 방법들이 있다.

- 브라우저 캐시 무효화
    - max-age설정이나 핑거프린팅 같은 기법을 사용할 수 있다.

**캐시 워밍**이란 첫 요청 전에 캐시를 항목으로 미리 채워놓는 것을 의미한다. 워밍업의 그 워밍인가 보다.
이 방식을 사용하는 이유는 캐시 미스를 줄여서 낮은 지연시간을 사용자에게 제공하는 것이다. 다만 단점들이 존재한다.

- 복잡성이 증대한다. 만약 호스트가 수 천개라면 이를 워밍하는 것 자체가 복잡하고 비용이 많이들 수 있다. 
- 부하가 존재할 수 있다. 
- 캐시 만료시간이 짧으면 워밍을 해오는 것 자체가 낭비가 될 수 있다. 

-----

## 총평

데이터베이스에 대한 여러 얘기, 추가로 캐시 서비스에 대한 여러 이야기를 볼 수 있었다. 내용이 복잡하지는 않았으나 방대하고 여러 기버베 대해 설명해서 그런지 정리할 것도 많았다.

데이터베이스는 아무래도 높은 가용성고 일관성 등 고려해야할 부분이 많다보니 얘기할 내용도 굉장히 방대하고 중요했던 것 같다.