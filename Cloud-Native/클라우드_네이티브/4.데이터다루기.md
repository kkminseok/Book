데이터베이스에 관한 이야기

## 데이터 스토리지 시스템

- 퍼블릭 클라우드 공급자들은 오브젝트 스토리지 서비스를 제공함.
  - 데이터를 오브젝트로 관리함.
- 데이터베이스
  - 키/값 데이터베이스
  - 문서 데이터베이스
  - 관계형 데이터베이스
  - 그래프 데이터베이스
  - 컬럼 패밀리
  - 시계열 데이터베이스
  - 검색 엔진 데이터베이스
- 스트림과 큐
  - 컨슈머는 특정위치에 있는 스트림에서 이벤트를 읽을 수 있으나 제어는 불가능
  - 메시징 큐나 토픽은 큐에서 개별 메시지 제어가 가능하다. 
  - 큐는 서비스간 통신에 자주 사용됨. 
  - 스트림은 이벤트를 연속해서 기록하기 좋고 스트리밍 시스템은 일반적으로 대량의 데이터를 저장하고 처리 가능
- 블록체인
  - 레코드들은 블록으로 그룹화되고, 각각은 데이터베이스에 일정 개수의 레코드들을 가짐. 새 레코드가 생성될 때마다 하나의 블록으로 그룹화되어 체인에 추가됨. 블록은 변조되지 않았다는 걸 보장하는 해싱을 이용해서 함께 연결됨. 블록의 데이터를 조금만 변경하면 해시가 바뀜. 이로인해서 탈중화함.
- 데이터 베이스 선택 
  - 데이터 형식, 종류
    - 어떤 종류의 데이터 저장해야허는지?
  - 읽고 쓰기
    - 데이터를 어떻게 읽고 쓰는지?
  - 데이터 크기
    - 데이터스토어에 들어갈 데이터 얼마나 큰지?
  - 규모와 구조
    - 필요한 스토리지 용량은 얼마고, 파티셔닝이 필요한지?
  - 데이터 관계
    - 복잡한 관계를 지원해야 하는 데이터인지?
  - 일관성 모델
    - 강력한 일관성이 필요한지?
  - 스키마 유연성
    - 어떤 종류의 스키마가 데이터에 적용될 것인지?
  - 동시성
    - 동시성 제어가 필요한지?
  - 데이터 이동
    - 데이터를 다른 스토어나 데이터 웨어하우스로 옮겨야하는지?
  - 데이터 생명 주기
    - 데이터가 한 번 쓰고 많이 읽는지?
  - 스트림 변경
    - CDC를 지원하고 데이터 변경 시 이벤트를 발생시켜야하는지?
  - 다른 지원 가능한 기능들
    - 인덱싱, 풀텍스트 검색 등 기능이 필요한지?
  - 팀 경험
  - 지원
  - 성능과 확장성
    - 쿼리와 분석이 필요한지?
  - 신뢰성
  - 복제
    - 리전이나 존에 걸쳐 데이터 복제해야하는지?

## 다양한 데이터 스토어 데이터

여러 파티션, 데이터베이스, 서비스에 나눠져 있는 데이터로 작업하는 것은 데이터 관리에 어려움을 유발함.

- 여러 데이터베이스 사이의 데이터 일관성
- 여러 데이터베이스에 있는 데이터의 분석
- 여러 데이터베이스의 백업과 복구

이런 과제가 주어진다.

데이터 변경 이벤트 스트림을 제공하고 사용하기 쉬운 API를 노출해 트리거링을 시킴.

즉 데이터베이스에 변경이 생기면 스트림에 해당 내용을 쓰고 여러 컨슈머가 이를 보고 처리함. 

CDC의 일반적인 사례는 다음과 같다.

- 알림
- 구체화 뷰
- 캐시 무효화
- 감사
- 검색
- 분석
- 변경 분석
- 아카이브
- 레거시 시스템

다만 이런 방식의 문제점은 하나가 실패하면 경쟁조건이 생길 수 있고 동시에 레코드 하나를 변경하면 이벤트 순서가 꼬일 수도 있다는 점이다. 

변경 사항을 먼저 스트림에 기록했다가 적용하는 것으로 문제를 해결할 수도 있다. 

### 트랜잭션 관리자

관리자 서비스를 이용해 트랜잭션을 성공적으로 완료하거나 보상하도록 보장 가능하다.

시스템과 데이터베이스의 일관성을 모니터링해서 올바르게 수정하거나 문제에 대한 알림을 보내기 위해 관리자를 이용하고 상태를 설정하는 다양한 방법으로 사용이 가능

### 보상 트랜잭션

파일쓰기 이후 데이터베이스에 저장한다면 만약 데이터베이스 쓰기가 실패한 경우 보상으로 파일이 반드시 삭제되어야한다는 것. 이것이 보상 트랜잭션이 하는 일

### 추출, 변환, 로드(ETL)

한 시스템에서 다른 시스템으로 데이터를 옮길 때 추출, 변환, 로드 플랫폼을 사용. 이를 ETL플랫폼이라고함. AWS GlUE, Azure Data Factory 등이 있음

### 마이크로서비스와 데이터 레이크

분산된 데이터들을 어떻게 리포팅하고 분석할 것인가. 일반적으로 중앙 데이터스토어에 집계를 위한 데이터들을 다 모아버림. 이러면 결합도가 높아지긴함. 이를 해결하기 위한 다양한 방법이 있다.

- 데이터가 저장되어있는 서비스 데이터베이스에 직접 접근하여 가져오거나
  - 규모가 작은 초기에는 괜찮을 수도 있다.
- 통합용 데이터베이스를 프로비전하고 관리하거나
  - 이 경우 서비스에 직접 접근하지 않으므로 부하가 줄어들 수 있음.
- 서비스쪽에서 데이터를 내보내거나
- 또 다른 외부 데이터베이스에 데이터를 저장하게끔 하는 등의 방법이 있다.

## 빠르게 확장 가능한 데이터

복제, 파티셔닝 등으로 확장할 수 있다.

### 데이터 샤딩

- 수평적 파티션으로 데이터스토어를 나누는 것
- 부하를 여러 데이터 스토리지 시스템으로 분산해서 시스템을 확장할 때 주로 사용
- 얼마나 많은 샤드를 사용할지, 데이터를 어떻게 샤드에 분산할 지 등 결정이 필요

### 데이터 캐싱
- 가장 큰 문제는 원본 데이터와 캐시된 데이터를 동기화 하는 부분
    - 캐시를 주기적으로 업데이트하는 백그라운드 서비스 이용 등

### 콘텐츠 전송 네트워크(CDN)

- 콘텐츠를 사용자 가까운 곳에 둬서 웹사이트 로딩 시간을 개선
- 특정 기간이 지나면 콘텐츠를 갱신하기 위해 콘텐츠 만료(TTL) 사용 권장
- 콘텐츠에 해시 또는 버전을 추가
- API등의 방법으로 캐시를 명시적으로 만료할 방법도 구축해두자.

## 데이터 분석

### 스트림

실시간으로 데이터 스트림을 분석하는 것은 분석 지연시간을 단축하는 방법. 

### 배치




## 총평

어렵다. 내용이 일단 상황을 가지고 얘기하는데, 그 부분이 공감되지 않아서 100% 이해하는게 쉽지 않다. 번역이 매끄러운 편이 아니기도해서 이 부분도 글을 읽는 몰입감을 해치는 것 같다. 내가 정리를 하면서 화자가 뭘 말하고 싶은건지? 잘 모르겠다.

내가 정리를 못하는 것도 있겠지만, 마냥 좋은 책은 아닌 것 같다.

